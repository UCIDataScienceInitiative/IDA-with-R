---
title: "Intro to Data Analysis with R: Session 3"
subtitle: UCI Data Science Initiative
date: "October 20, 2017"
#author: "Chris Galbraith"
output: slidy_presentation
smaller: yes
---

```{r, include=FALSE, echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Session 3 Agenda

1. Statistical Distributions (very brief) 

2. T-Tests

3. Linear Regression

    + Fitting Models
    + Interpretation
    + Diagnostics
    + Prediction


## Statistical Distributions in R:

+ R has many built-in statistical distributions
    + e.g., binomial, poisson, normal, chi square, ...

+ Each distribution in R has four functions:
    + These functions begin with a "d", "p", "q", or "r" and are followed by the name of the distribution

+ ```d<dist>()```: evaluates the probability density/mass function at a given value
+ ```r<dist>()```: generates random numbers
+ ```p<dist>()```: returns the cumulative distribution function (CDF) for a given quantile
+ ```q<dist>()```: returns the quantile for a given probability


## Standard Normal Distribution

+ Calculate the value of the probability density function at $X = 0$
```{r echo=TRUE}  
str(dnorm) # normal pdf
dnorm(x = 0, mean = 0, sd = 1)
```


## Standard Normal Distribution
```{r echo=TRUE, fig.height = 4.5, fig.align='center'}  
x <- seq(from = -3, to = 3, by = 0.05)
y <- dnorm(x, mean = 0, sd = 1)
plot(x, y, type = "l")
```

## Standard Normal Distribution

+ Generate 10 independent random numbers from a standard normal distribution
```{r echo=TRUE}  
str(rnorm) # generate random number from normal dist
rnorm(10, mean = 0, sd = 1)
```


## Standard Normal Distribution

+ Calculate the probability that $X \leq 0$
```{r echo=TRUE}  
str(pnorm) # normal CDF
pnorm(0, mean = 0, sd = 1) # Pr[X <= 0] = ?
```


## Standard Normal Distribution

+ Find the value for which the CDF = 0.975
```{r echo=TRUE}  
str(qnorm) # normal quantile func
qnorm(0.975, mean = 0, sd = 1) # PR[X <= ?] = 0.975
```


## T-Tests
T-tests can be used to draw statistical conclusions about parameters of interest in the data

+ Is the mean of this data different from zero (or another number)?

+ Are the means of two data sets different from one another?

+ Is the regression slope coefficient different from zero?

T-tests can be categorized into two groups:

1. One-sample t-test

2. Two-sample t-test


##  One-Sample T-Test (Create Data)
```{r echo=TRUE}
set.seed(123)
oneSampData <- rnorm(100, mean = 0, sd = 1)

mean(oneSampData)
sd(oneSampData)
```


##  One-Sample T-Test ($H_0: \mu = 0$)
```{r echo=TRUE}
oneSampTest.0 <- t.test(oneSampData) 
oneSampTest.0
```

```{r echo=TRUE}
names(oneSampTest.0) 
oneSampTest.0$statistic
oneSampTest.0$estimate
```  


##  One-Sample T-Test ($H_0: \mu = a$)
```{r echo=TRUE}
a <- 0.3
oneSampTest.mu <- t.test(oneSampData, mu = a)
oneSampTest.mu
```  


##  Two-Sample T-Test
Two sample t-tests are categorized into 3 groups:

  + T-Test with equal variances
  
  + T-Test with un-equal variances
  
  + Paired T-Test (one-sample t-test on differences)


##  Two-Sample T-Test (Create & Plot Data)
```{r echo = TRUE}
Samp1 <- rnorm(300, mean = 2.5, sd = 1)
Samp2 <- rnorm(500, mean = 3.0, sd = 1) # notice: not the same sample size
plot(density(Samp1), col="red", main="Densities of Samp1 and Samp2", xlab="")
abline(v = mean(Samp1), col = "red", lwd = 2, lty=2)
lines(density(Samp2), col="blue")
abline(v = mean(Samp2), col = "blue", lwd = 2, lty = 2)
legend("topright", legend = c("Samp1", "Samp2"),
       fill = c("red","blue"), bty = "n", cex = 1.3)
```


##  Two-Sample T-Test (Un-equal Variances)
Null hypothesis: $\mu_1 = \mu_2 \Leftrightarrow \mu_1 - \mu_2 = 0$
```{r echo = TRUE}
t.test(Samp1, Samp2)  # default assump: unequal variances
```


##  Two-Sample T-Test (Equal Variances)
Null hypothesis: $\mu_1 = \mu_2 \Leftrightarrow \mu_1 - \mu_2 = 0$
```{r echo = TRUE}
t.test(Samp1, Samp2, var.equal = TRUE)  # default assump: unequal variances
```


##  Two-Sample T-Test (Paired T-Test)
Let $D \equiv \{x_i - y_i : i=1, \ldots, n \}$, then

Null hypothesis: $\mu_D = 0$
```{r echo = TRUE}
t.test(Samp1, Samp2[1:300], paired = TRUE) # must be of the same sample size
```


## Linear Regression Data Set Description
Here we use the "Prestige" dataset from the `car` package, which has the following variables

+ education: Average education of occupational incumbents, years, in 1971.

+ income: Average income of incumbents, dollars, in 1971.

+ women: Percentage of incumbents who are women.

+ prestige: Pineo-Porter prestige score for occupation, from a social survey conducted in the mid-1960s.

+ census: Canadian Census occupational code.

+ type: Type of occupation, a factor with levels 

    + bc: Blue Collar
    + prof: Professional, Managerial, and Technical
    + wc: White Collar


## Load Data
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
prestige <- read.csv(file="/Users/CMG/dev/IDA-with-R/data/prestige_v2.csv", 
                     row.names=1)  # path will vary
str(prestige)
head(prestige)
```


<!-- ## Examine Observations with NA values -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- Prestige[is.na(Prestige$type),] -->
<!-- ``` -->

<!-- Find their row indices and corresponding names... -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- ind <- which(is.na(Prestige$type))  # gives index numbers of the NAs in the vector -->
<!-- rbind(index=ind, name=rownames(Prestige)[ind])  # print index with rowname -->
<!-- ``` -->


<!-- ## Recode/Drop NA Values -->
<!-- Let's recode newsboys, babysitters, and farmers as blue collar and exclude athletes. -->

<!-- Use `rep()` to create a vector with 3 elements of "bc" -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- ind.ch <- ind[-1] -->
<!-- Prestige[ind.ch,"type"] <- rep("bc", 3) -->
<!-- summary(Prestige$type) -->
<!-- ``` -->

<!-- Exclude athletes... -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- Prestige <- na.omit(Prestige)  -->
<!-- summary(Prestige$type) -->
<!-- ``` -->


<!-- ## Plotting - Histograms -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- hist(Prestige$prestige, col = "grey",  -->
<!--      main = "Histogram of Prestige Score", xlab = "Prestige Score") -->
<!-- ``` -->


<!-- ## Plotting - Basic Scatter Plot -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- plot(Prestige$education, Prestige$prestige, -->
<!--      main = "Prestige Score by Education", -->
<!--      xlab = "Ave. Years of Education", ylab = "Prestige Score") -->
<!-- ``` -->


<!-- ## Plotting - Including Regression/Smoother Lines -->
<!-- `abline()` adds a line to the plot, and `lm()` is a list object that contains regression coefficients. -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- plot(Prestige$education, Prestige$prestige, -->
<!--      main = "Prestige Score by Education", -->
<!--      xlab = "Avg Years of Education", ylab = "Prestige Score") -->
<!-- abline(reg = lm(prestige ~ education, data = Prestige), col = "red", lwd = 2) -->
<!-- lines(lowess(Prestige$education, Prestige$prestige), col = "blue", lty = 2, lwd = 2) -->
<!-- legend("topleft",legend = c("Regression Line", "Smoother"), col = c("red","blue"), -->
<!--        lwd = c(2,2), lty = c(1,2), bty = "n") -->
<!-- ``` -->


<!-- ## Plotting - Scatter Plot Matrix -->
<!-- Use the `scatterplotMatrix()` function from the `car` package -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- # Use direct ordering of the varaibles to control how they are plotted -->
<!-- scatterplotMatrix(Prestige[,c("prestige","education","income","women")]) -->
<!-- ``` -->


<!-- ## Plotting - Boxplots  -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- boxplot(prestige ~ type, data = Prestige, col = "grey", -->
<!--         main = "Distribution of Prestige Score by Types", -->
<!--         xlab = "Occupation Types", ylab = "Prestige Score") -->
<!-- ``` -->


<!-- ## Linear Regression - Fit the Model -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- myReg <- lm(prestige ~ education + income + women, data = Prestige) -->
<!-- myReg -->
<!-- names(myReg) -->
<!-- ``` -->


<!-- ##  Linear Regression - Summary of Fit -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- summary(myReg) -->
<!-- ``` -->


<!-- ##  Linear Regression - "summary" Contents -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- sum.myReg = summary(myReg) -->
<!-- names(sum.myReg) # show different contents -->

<!-- names(myReg) # this is what we had previously -->
<!-- ``` -->


<!-- ##  Linear Regression - Confidence Interval -->
<!-- + 95% confidence interval for coefficient of 'income' -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- confint(myReg, 'income', level=0.95) -->
<!-- ``` -->

<!-- + 95% confidence interval for each coefficient -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- confint(myReg, level=0.95) -->
<!-- ``` -->


<!-- ##  Linear Regression - Adding Variables -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- mod = update(myReg, ~ . + type); summary(mod) -->
<!-- ``` -->


<!-- ##  Linear Regression - Relevel a Factor -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- levels(Prestige$type) -->
<!-- Prestige$type = relevel(Prestige$type, "prof") -->

<!-- levels(Prestige$type) -->
<!-- ``` -->


<!-- ##  Linear Regression - Relevel a Factor -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- mod = update(myReg, ~ . + type); summary(mod) -->
<!-- ``` -->


<!-- ##  Linear Regression - Diagnostics -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE, fig.height=6.5, fig.width=8} -->
<!-- par(mfrow = c(2, 2), oma = c(0, 0, 2, 0)) -->
<!-- plot(myReg) -->
<!-- ``` -->


<!-- ##  Linear Regression - Predict -->
<!-- Predict the output for a new input -->
<!-- ```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE} -->
<!-- newData = data.frame(education=13.2, income=12000, women=12) -->
<!-- predict(myReg, newData, interval="predict") -->
<!-- ``` -->


<!-- ## End of Session 4 -->
<!-- BREAK! -->



